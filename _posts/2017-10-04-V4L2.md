---
layout: post
title: v4l2&#58; An Introduction
tags: systems, linux, cameras, usb
---

v4l is the video for linux library, appropriately named. Most USB webcams utilize v4l to interface with the camera at a low-level, to obtain information and to program the camera to a specific output. In this case, v4l acts like more of a driver and API, and most USB cameras are programmed to interface with v4l on Linux. It's derived from V4W (Video 4 Windows), hence where it gets its name. In this post, we will cover obtaining information from the camera, and then programming the camera to grab a frame. We'll use the [ROS usb_cam](https://github.com/ros-drivers/usb_cam) driver as our example.

## v4l2-utils&#58; A start to webcam interfacing

Once you've plugged your webcam in, install the `v4l-utils` library:

```
sudo apt install v4l-utils
```

Now you have access to the `v4l2-ctl` command, which is the command line version of what we're going to do. `v4l2-ctl` is incredibly useful - you can list and set a lot of information about the camera. First, let's get a list of our devices:

```
$ v4l2-ctl --list-devices
Lenovo EasyCamera (usb-0000:00:1d.0-1.6)
       /dev/video0
```

This tells us we have a USB webcam connected on `/dev/video0`, called `Lenovo EasyCamera`. Let's find out what we can output from it:

```
$ v4l2-ctl --list-formats-ext
ioctl: VIDIOC_ENUM_FMT
	Index       : 0
	Type        : Video Capture
	Pixel Format: 'MJPG' (compressed)
	Name        : Motion-JPEG
		Size: Discrete 1280x720
			Interval: Discrete 0.033s (30.000 fps)
		Size: Discrete 640x480
			Interval: Discrete 0.033s (30.000 fps)
		Size: Discrete 320x240
			Interval: Discrete 0.033s (30.000 fps)
		Size: Discrete 160x120
			Interval: Discrete 0.033s (30.000 fps)
		Size: Discrete 800x600
			Interval: Discrete 0.033s (30.000 fps)

	Index       : 1
	Type        : Video Capture
	Pixel Format: 'YUYV'
	Name        : YUYV 4:2:2
		Size: Discrete 1280x720
			Interval: Discrete 0.100s (10.000 fps)
		Size: Discrete 640x480
			Interval: Discrete 0.033s (30.000 fps)
		Size: Discrete 320x240
			Interval: Discrete 0.033s (30.000 fps)
		Size: Discrete 160x120
			Interval: Discrete 0.033s (30.000 fps)
		Size: Discrete 800x600
			Interval: Discrete 0.067s (15.000 fps)

```

Here we get a bunch of information about the formats, resolutions, and framerates this camera runs at, and which ones we can select to obtain our camera image at. You'll notice that the MJPG resolutions allow us to run any resolution at 30 fps, because it's compressed and therefore not the full size. On the other hand, the YUYV format is totally uncompressed, and as a result cannot run at the fastest framerate at the highest resolution, due to issues with the memory buffer at the camera. If you try to run at a faster framerate, you'll get very randomized images that don't make sense.

With that in mind, how do we program these?

## IOCTLs: The interface of choice

The way most drivers interact with their hardware is called an __ioctl__, or I/O control. With an ioctl, we can send commands and receive data from the device, based on a specific constant and struct we send. The ioctl function is a system call which looks like this:

```c++
int ioctl(int fd, unsigned long request, void* arg)
```

The `arg` parameter indicates a pointer to any kind of other information we need, including one that contains height, width, and other image information.

Here, ROS writes a wrapper around the ioctl function in order to keep trying the ioctl until we succeed (or get an error):

```c++
static int xioctl(int fd, int request, void * arg)
{
    int r;

    do
        r = ioctl(fd, request, arg);
    while (-1 == r && EINTR == errno);

    return r;
}
```

## Starting the device

First, we need to open our file descriptor to the webcam:

```c++
int fd = open("/dev/video0", O_RDWR | O_NONBLOCK, 0);
```

Each device in Linux is given a file descriptor to address it individually, and to provide an interface to read/write to the device. The `open` call allows for the device to be opened by this program only, and to allow program execution to continue and return immediately instead of waiting for the entire system call to finish. Opening this file descriptor gives us access to the device for reading / writing parameters to the device.

First, let's query the capabilities of the device:

```c++
struct v4l2_capability cap;
xioctl(fd, VIDEOC_QUERYCAP, &cap);
```

(Note that you should really check if this ioctl returns -1, or error. For the sake of brevity, I'm skipping that step.)

The `v4l2_capability` struct contains the following fields:

* driver name
* card name
* the bus information (i.e. which memory bus the device is plugged into)
* capabilities (the things the device can do, in general, such as read/write info)
* device_capabilities (only set if a specific flag in capabilities is set)
* reserved (not used)

Some capabilities that can be found is

* V4L2_CAP_VIDEO_CAPTURE (video capture)
* V4L2_CAP_RADIO (this device is a receiver radio)
* V4L2_CAP_READWRITE (Read/write is supported on this device)

Here, we're going to check two specific conditions: V4L2_CAP_VIDEO_CAPTURE and V4L2_CAP_STREAMING, which tells us if we can capture and stream video:

```c++
if(!((cap.capabilities & V4L2_CAP_STREAMING) && (cap.capabilities & V4L2_CAP_STREAMING)))
{
    return -1;
}
```

Next, we're going to check for a crop, and reset it to a default. A crop basically means the camera reduces the size of the image by removing the edges and returning only the center of the image. Since we don't really want a crop, we're going to reset it to the default (which is usually none):

```c++
struct v4l2_cropcap cropcap;
struct v4l2_crop crop;

if (0 == xioctl(fd_, VIDIOC_CROPCAP, &cropcap))
{
    crop.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    crop.c = cropcap.defrect; /* reset to default */

    if (-1 == xioctl(fd_, VIDIOC_S_CROP, &crop))
    {
      return -1;
    }
}
else
{
  /* Errors ignored. */
}
```

Now, we need to set the formats of the camera itself, including the resolution, framerate, and pixel format. Note that is is **important** that you choose a resolution and framerate that is in line with the resolution/framerates supported by the camera. If you don't, then nothing will work, or it'll be off and on.

We do that using the `v4l2_format` structure, which contains all these fields, as well as a few more. We fill in these fields as follows, then call the ioctl:

```c++
struct v4l2_format fmt;
fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
fmt.fmt.pix.width = image_width;
fmt.fmt.pix.height = image_height;
fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;
fmt.fmt.pix.field = V4L2_FIELD_INTERLACED;

xioctl(fd, VIDEOC_S_FMT, &fmt);
```

For now, we're going to capture raw video, since raw > compressed always. (Not really, but MJPG requires decoding, which is a process for another time. Raw is just easier.)

Now, we need to set the parameters for streaming from the device, which include the framerate. First we get the parameters and store them in `stream_params`.

```c++
struct v4l2_streamparm stream_params;
memset(&stream_params, 0, sizeof(stream_params));
stream_params.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
xioctl(fd, VIDIOC_G_PARM, &stream_params);
```

Now, we should set the framerate. This involves using two parameters, a numerator and a denominator, with the framerate (in fps) going in the denominator:

```c++
stream_params.parm.capture.timeperframe.numerator = 1;
stream_params.parm.capture.timeperframe.denominator = framerate;
xioctl(fd, VIDEO_S_PARM, &stream_params);
```

Now, we've set up all the stuff relating to the actual camera, telling it to stream and capture information. Next, we'll set up a method to actually read the image into a buffer.

## Initializing the Memory Map

Here, we're going to memory map the address space where the camera will put the image into our own buffer, so we can read it and decode it and do image processing stuff on it later. First, let's initialize the method we're going to use (MMAP) and the number of buffers we have. Note that there are other, probably easier methods to do this, but mmap is widely used, and doesn't rely on the camera to have implemented any kind of method. If your camera has implemented Read/Write though, use that - it's a lot easier.

```c++
struct v4l2_requestbuffers req;

req.count = 4;
req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
req.memory = V4L2_MEMORY_MMAP;

xioctl(fd, VIDIOC_REQBUFS, &req);
```

Now that we've requested the buffers on the camera, let's allocate some of our own buffers to actually read the image into:

```c++
struct buffer
{
  void * start;
  size_t length;
};
buffer* buffers_;
buffers_ = (buffer*)calloc(req.count, sizeof(*buffers_));
```

Finally, we need to assign the buffers to the camera buffers using the `mmap` function:

```c++
int n_buffers_;
for (n_buffers_ = 0; n_buffers_ < req.count; ++n_buffers_)
{
    struct v4l2_buffer buf;

    CLEAR(buf);

    buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    buf.memory = V4L2_MEMORY_MMAP;
    buf.index = n_buffers_;

    if (-1 == xioctl(fd_, VIDIOC_QUERYBUF, &buf))
      errno_exit("VIDIOC_QUERYBUF");

    buffers_[n_buffers_].length = buf.length;
    buffers_[n_buffers_].start = mmap(NULL, // start anywhere
            buf.length, PROT_READ | PROT_WRITE, // required
	    MAP_SHARED, // recommended
	    fd, buf.m.offset);

    if (MAP_FAILED == buffers_[n_buffers_].start)
      errno_exit("mmap");
}
```

Here, we map the buffers of each of the cameras into the buffers of our local variable, setting the buffer's length to be the length of the camera's buffer. Now, we can read from our local buffer variable, instead of having to read from the camera's buffer, and giving us direct access to the camera's image buffer.

Now, we are (almost) ready to start capturing images!

## Starting streaming

To start the camera streaming directly into our buffers, we need to first query the buffers to see if they are ready:

```c++
for (i = 0; i < n_buffers_; ++i)
{
    struct v4l2_buffer buf;

    CLEAR(buf); // set the buf variable to zero using memset

    buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    buf.memory = V4L2_MEMORY_MMAP;
    buf.index = i;

    xioctl(fd_, VIDIOC_QBUF, &buf);
}
```

Now, if the buffer queries are all successful, we should tell the camera to turn the streaming on:

```c++
enum v4l2_buf_type type;
type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
xioctl(fd_, VIDIOC_STREAMON, &type);
```

Now, our camera is officially capturing images!

## Grabbing images

... but we still need to grab them.

To get the images, we get the next file descriptor (which holds the images) and we wait for the image to come in using the `select` function. This function will block the calling process until a file on the file descriptor is ready to be read, or it times out. We set a timeout period of a couple seconds:

```c++
fd_set fds;
struct timeval tv;
int r;

FD_ZERO(&fds);
FD_SET(fd_, &fds);

/* Timeout. */
tv.tv_sec = 5;
tv.tv_usec = 0;

r = select(fd_ + 1, &fds, NULL, NULL, &tv);
```

Note that select returns -1 in case of an error, or 0 in case of timeout.

To access the image, we first send the value of VIDEOC_DQBUF to the camera, telling it that we are ready to access the buffer, so it should send it over:

```c++
struct v4l2_buffer buf;
unsigned int i;
int len;

buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
buf.memory = V4L2_MEMORY_MMAP;

xioctl(fd_, VIDIOC_DQBUF, &buf);
```

Now, since we memory mapped the camera buffer into our local buffers, we can just access the data in our local buffer!

```c++
len = buf.bytesused;
process_image(buffers_[buf.index].start, len, image_);
```

Here, `buf.index` tells us which of the buffers the current image is stored in, as well as the length of the entire image. We can use that to process the image and read it into a way we can understand. The image processing will come in a later post, but the idea is that now you have access to a 3 channel YUV image which you can transform to any other kind of image.

## Destroying everything

Once you get sick of reading in images, we need to clean everything up. First we need to turn of streaming using an ioctl:

```c++
enum v4l2_buf_type type;
type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
xioctl(fd, VIDIOC_STREAMOFF, &type);
```

Next, we need to de-initialize the memory map:

```c++
for (i = 0; i < n_buffers_; ++i)
    munmap(buffers_[i].start, buffers_[i].length);
```

And finally, close the device descriptor:

```c++
close(fd);
```

Destroying everything is a lot easier than setting it up, like most things in life.

## Conclusion

In this tutorial, we built a program to connect to a USB camera, read images, and disconnect. With this, you should be able to connect to any webcam on Linux in the market today. Note that this won't work for very high-end cameras which have their own APIs (although, if configured correctly, it might). You should also be careful to not go over the limits of the camera (you're not going to be able to stream 4k @ 120fps on any webcam in the market) so read the specs and formats using `v4l2-ctl` carefully. Thankfully most cameras will just return -1 in case you try something like that, but still don't try it. If you want to see the full implementation of the ROS driver, it's available [here](https://github.com/ros-drivers/usb_cam/blob/develop/src/usb_cam.cpp).


## References
http://man7.org/linux/man-pages/man2/ioctl.2.html

https://www.kernel.org/doc/html/latest/media/uapi/v4l/vidioc-querycap.html

http://man7.org/linux/man-pages/man2/mmap.2.html

http://v4l-test.sourceforge.net/spec/r12878.htm

https://www.gnu.org/software/libc/manual/html_node/Waiting-for-I_002fO.html
