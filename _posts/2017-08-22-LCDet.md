---
layout: post
title: Paper Review&#58; LCDet&#58; Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems
tags:
- research
- computer-vision
- papers
---


Here's an interesting paper about reducing the memory and bandwidth of a deep neural network while still obtaining comparable accuracy. LCDet was presented this year at CVPR 2017. The paper can be found [here](https://vision.cornell.edu/se3/wp-content/uploads/2017/07/LCDet_CVPRW.pdf).

### Introduction

Deep learning currently isn't very applicable for a lot of low-power embedded applications. As someone who worked on several low-power applications, using deep learning often wasn't worth it - it was too slow and too memory-clogging for it to be useful. For a task like object detection, before ConvNets were a thing, people used Viola-Jones detectors [1], which worked decently, but often struggled with changes in lighting and scene. With the advent of convolutional networks, people started using deep learning for object detection, such as R-CNN [2], Faster R-CNN [3], and YOLO (You only look once) [4]. Real-time object detection has only been achieved recently, and with a high performance cost (2 Tesla K40s for YOLO). There would be a lot of demand for a system we could run on a mobile phone or an ARM processor.

LCDet (Low-Complexity Detection) is a neural network based off of YOLO, but with the network size reduced by 3x as well as the memory usage reduced by 3-4x as compared to the original YOLO network. The authors discuss the network architecture, training, and ways they reduced the number of parameters as well as the total memory bandwidth. The authors then test their code using TensorFlow on several face detection datasets.

### Network architecture

![Img](http://mohsaad.com/imgs/lcdet.png)

LCDet is essentially the same network as normal YOLO, with the last two layers cut off and replaced with two fully-convolutional layers, which reduces the number of parameters by 115x, requiring 2.3 x 10^6 parameters (down from 269 x 10^6). The Leaky ReLu layers are also replaced by normal ReLus, and the last layer applies different activations depending on the output (softmax for classification, sigmoid for confidence, and no activation for localization). The network, like YOLO, is trained end-to-end.

During training, the authors apply a multi-part object detection loss, optimizing over classification and localization error and attempting to minimize both. The model uses 448x448 pixel inputs for training and testing.

After training, the authors quantize the model to an 8-bit fixed-point model. While normally people would train and test on an 8-bit fixed-point numbers, the authors decided that since we're not learning online, we can just train, quantize, and then use the resulting model in our detection pipeline. The authors actually don't know why the resulting model works as well without training in the 8-bit mode, but it seems to work well for low-precision inference.

### Experimental results

The authors evaluated the resulting network on the FDDB and Widerface datasets, although it is not limited to just faces. To test, they used transfer learning to create a Tensoflow model, and then retrained the last two layers to accomplish the objective.

The detection accuracy is comparable to regular YOLO, with the ReLu's working better than the LeakyReLu's for detection. The quantized model also performs only slightly worse than the floating point model, with similar curves for the true vs false positive rate.

As for performance, the authors report a 20x speedup in framerate on several embedded devices including a recent Snapdragon model. The bandwidth that LCDet requires is only about 1 Gbps, much smaller than the 20 Gbps needed for normal YOLO.

Some issues I saw with this was LCDet's inability to pick up smaller faces or faces that overlap greatly. While for most applications this isn't a super high priority, this could limit its usefulness for some specific criteria. If the image is especially small, I noticed it sometimes didn't pick it up at all, which is not good.

### Conclusion

Overall, though, LCDet seems to work pretty well at reducing the model size and compressing it down. It has its issues with smaller objects, but for a general purpose model it seems to do alright.

### References

[1]&#58; Viola, Paul, and Michael J. Jones. "Robust real-time face detection." International journal of computer vision 57.2 (2004): 137-154.

[2]&#58; Girshick, Ross, et al. "Rich feature hierarchies for accurate object detection and semantic segmentation." Proceedings of the IEEE conference on computer vision and pattern recognition. 2014.

[3]&#58; Ren, Shaoqing, et al. "Faster R-CNN: Towards real-time object detection with region proposal networks." Advances in neural information processing systems. 2015.

[4]&#58; Redmon, Joseph, et al. "You only look once: Unified, real-time object detection." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.
